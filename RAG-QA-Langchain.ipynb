{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3486d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain import HuggingFaceHub\n",
    "import os\n",
    "import torch\n",
    "import textwrap\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"<your HF token>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e58fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the document\n",
    "loader = PyPDFLoader('/Users/indira/Documents/Indira/Tech/Books/nnlp.pdf')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5f9e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the document\n",
    "text_splitter = CharacterTextSplitter('\\n' , chunk_size=1000 , chunk_overlap = 50)\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf73907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f234c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2') #,model_kwargs={'device': 'cuda'})\n",
    "#2. Vector store\n",
    "vectorstore=Chroma.from_documents(text_chunks, embeddings)\n",
    "#3. Generator model\n",
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":1, \"max_length\":1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff90db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RetrievalQA chain\n",
    "chain =  RetrievalQA.from_chain_type(llm=llm, \n",
    "                                     chain_type = \"stuff\",\n",
    "                                     return_source_documents=True, \n",
    "                                     retriever=vectorstore.as_retriever())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8481eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs\n",
      "Wall time: 22.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Larger windows tend to produce more topical similarities (i.e. dog\", bark\" and leash\" will be grouped together, as well as walked\", run\" and walk- ing\"), while smaller windows tend to produce more functional and syntactic similarities'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "query = \"How does the size of sliding window matter?\"\n",
    "result=chain({\"query\": query}, return_only_outputs=True)\n",
    "wrapped_text = textwrap.fill(result['result'], width=500)\n",
    "wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c637a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39580e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can pass the pipeline as input llm to langchain \n",
    "## or load the model using HuggingFaceHub\n",
    "## Pipeline not supported for T5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31bd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm] *",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
